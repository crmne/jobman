.. _addition_exp_sql:

Use Case: using SQL
==========================

This chapter outlines how to use Jobman in conjunction with a PostgreSQL
or SQLite database, for storing both hyperparameters and results.

Note that if you want to share the database with more than one machine
you must use PostgreSQL.  Do not attempt to share a sqlite database
over NFS or any other file-sharing system.  To quote the SQLite
documentation:

  A good rule of thumb is that you should avoid using SQLite in
  situations where the same database will be accessed simultaneously
  from many computers over a network filesystem.

URL syntax
----------

The generic URL syntax is

.. code-block:: console

   driver://[user[:pass]@]host/dbname?table=tablename

where you supply your own ``driver``, ``user``, ``pass``, ``host``,
``dbname`` and ``tablename``.

More specifically, for PostgreSQL you would use:

.. code-block:: console

   postgres://[user[:pass]@]host/dbname?table=tablename

and for SQLite (for a relative database path):

.. code-block:: console

   sqlite:///path/to/db?table=tablename

or (for an absolute path):

.. code-block:: console

   sqlite:////path/to/db?table=tablename

The rest of this document will use PostgreSQL urls in the examples
since it is, most of the time, the right choice.

The ``experiment`` function
---------------------------

This section will focus on the following use-case (first shown in the
Introduction):

.. code-block:: python

    def addition_example(state, channel):
        print 'state.first =', state.first
        print 'state.second =', state.second

        state.result = state.first + state.second

        print 'result =', state.result

        return channel.COMPLETE

However, we will see how to run the above program using parameters stored in
the database.


Inserting jobs in the database
------------------------------

There are two ways one can insert jobs in a database: from the command line
and from a python script.

From the Command Line
.....................

To insert jobs into the database from the command line, use the ``jobman
sqlschedule`` command. An example is given below:

.. code-block:: bash

    jobman sqlschedule postgres://user[:pass]@host/dbname?table=tablename \
           path.to.experiment first=1 second=3

This will insert a single experiment into the table ``<tablename>`` of database
``<dbname>``, with parameters ``first=1`` and ``second=3``. If the tables in the DB
do not exist, they will be created through this command. Note that by default,
duplicate jobs are not inserted in the DB. To force insertion of a duplicate
job, use the ``-f`` flag.

``jobman sqlschedule`` also support the ``key=value``, ``key::builder`` and/or ``key:=expression`` syntax that :ref:`jobman cmdline <cmdline>` support.

.. code-block:: bash

   # Example
   jobman sqlschedules postgres://user[:pass]@host/dbname?table=tablename \
          jobman.experiments.print_state first=3 \
	  "uniform:=@random.uniform(0, 100)" "gaussian:=@random.random()"

   # To run them(explained later):
   jobman sql -n 4 postgres://user[:pass]@host/dbname?table=tablename .

Multiple jobs
.............

The ``sqlschedules`` command may be used to insert many jobs at once. The
parameter syntax to use is then:

.. code-block:: bash

    jobman sqlschedules postgres://user[:pass]@host/dbname?table=tablename \
           path.to.experiment first="{{1,2,3,4}}" second=3 third="{{3,5,6}}" \
	   "uniform:=@random.uniform(0, 100)" "gaussian:=@random.random()"

This will take all permutations of parameters ``first``, ``second``
and ``third`` and insert 12 jobs in the table. The ``{{}}``, must be
quoted, otherwise the shell will interpret itself the outer ``{}``.

This syntax can be fixed with the previous syntax.

For more details, see ``jobman help sqlschedule`` and ``jobman help sqlschedules``.


From a Python Script
....................

Inserting jobs through a Python script is probably a more flexible way to
insert MANY jobs at once in the database.

For instance, if you want to apply the previous experiment function to
different values of ``first`` and ``second``, like all even numbers
between 0 and 10 for ``first``, and odd numbers in the same range for
``second``.

You can then write the following code:

.. code-block:: python

    from jobman.tools import DD, flatten
    from jobman import api0, sql
    from jobman.examples.def_addition import addition_example

    TABLE_NAME='test_add_'

    # DB path...
    db = api0.open_db('postgres://<user>:<pass>@<server>/<database>?table='+TABLE_NAME)

    state = DD()
    for first in 0,2,4,6,8,10:
        state.first = first
        for second in 1,3,5,7,9:
            state.second = second

            sql.insert_job(addition_example, flatten(state), db)


That would insert 30 jobs into the database.

Executing the jobs
------------------

Once the specifications of the job (the experiment function and its
arguments) are inserted into the database, they can be retrieved and
executed on any machine with access to this database.

The files that will be produced during the execution will be placed in a
unique subdirectory of the experiment root path, provided when launching
the job. For instance, if you want the experiment root to be the current
directory:

.. code-block:: bash

    jobman sql postgres://<user>:<pass>@<server>/<database>?table=<table> .

You can also specify a distant path, if you want to gather results from
jobs executed on different machines:

.. code-block:: bash

    jobman sql postgres://<user>:<pass>@<server>/<database>?table=<table> \
               ssh://<fileserver>:<some>/<path>

The above commands will retrieve one job description among those with
highest priority, and that have not been started yet, and execute
it. You can also ask for several jobs to be executed one after the
other:

.. code-block:: bash

    jobman sql -n3 postgres://<user>:<pass>@<server>/<database>?table=<table> .

will execute 3 jobs, and

.. code-block:: bash

    jobman sql -n0 postgres://<user>:<pass>@<server>/<database>?table=<table> .

will keep on executing new jobs until all jobs are executed. You can
launch this command on different computers, or several times on a
cluster, to have jobs executed in parallel.

To import modules before contacting the database, use the ``--import `` option. The 
following code

.. code-block:: bash

   jobman sql --import=numpy,theano postgres://<user>:<pass>@<server>/\
   <database>?table=<table> .

will import ``numpy`` and ``theano`` before executing the job.

For more information::

    jobman sql help

Querying the database
---------------------

In order to check on the newly inserted jobs, you can directly query the SQL
database containing them. In order to have a more user-friendly interface, an
SQL view can be created using either the command line or Python code.

An SQL view is an artificial table, which presents the data stored in SQL
tables in a different format. In our case, our standard SQL tables store
(key,value) in row format. The view will essentially take the transpose of this
table and create a single column from each unique key in the database. This
means that a single (query-able) column will be created for each unique key
within the ``state`` variable.

SQL restrictions on column names mean that:

* underscores in original key are dropped
  e.g. state.n_hidden_units becomes nhiddenunits
* dots in original key are converted to underscores: 
  e.g. state.rbm.nhid becomes rbm_nhid


Creating a View From the Command Line
.....................................

A view with name ``<viewname>`` can be created using the following::

    jobman sqlview postgres://user[:pass]@host/dbname?table=tablename viewname


Creating a View From a Python Script
....................................

A view can be created using the following python code:

.. code-block:: python

    from jobman import api0
    TABLE_NAME='test_add_'
    db = api0.open_db('postgres://<user>:<pass>@<server>/<database>?table='+TABLE_NAME)
    db.createView(TABLE_NAME + 'view')

You can also simply add the last line at the end of the job-insertion script.

Querying the View
.................

You can then log on to the database, for instance using psql command-line client::

    psql -h <server> -U <user> -d <database>

After entering your password, you can list the existing tables, where you should see:

.. code-block:: sql

    <database>=> \d
                          List of relations
     Schema |             Name              |   Type   |  Owner
    --------+-------------------------------+----------+----------
    [...]
     public | test_add_keyval               | table    | <user>
     public | test_add_keyval_id_seq        | sequence | <user>
     public | test_add_trial                | table    | <user>
     public | test_add_trial_id_seq         | sequence | <user>
     public | test_add_view                 | view     | <user>
    [...]
    (31 rows)


To see the whole view of your experiments:

.. code-block:: sql

    <database>=> SELECT * FROM test_add_view;

      id | first | jobman        |     jobman_hash      |jobman_sql|jobman | second 
         |       | _experiment   |                      |_priority |_status|
     ----+-------+----------------------+---------------+----------+-------+--------
       1 |     0 | <path_to_exp> |  2241733668524071315 |        1 |     0 | 1
       2 |     0 |     ...       |  -267140279470343327 |        1 |     0 | 3
       3 |     0 |     ...       | -6865789780955143209 |        1 |     0 | 5
       4 |     0 |     ...       | -2040929596669704635 |        1 |     0 | 7
       5 |     0 |     ...       | -3750366477946382133 |        1 |     0 | 9
       6 |     2 |     ...       |  2241733668522071305 |        1 |     0 | 1
       7 |     2 |     ...       |  -267140279468343317 |        1 |     0 | 3
       8 |     2 |     ...       | -6865789780957143219 |        1 |     0 | 5
       9 |     2 |     ...       | -2040929596667704625 |        1 |     0 | 7
      10 |     2 |     ...       | -3750366477948382143 |        1 |     0 | 9
      11 |     4 |     ...       |  2241733668528071327 |        1 |     0 | 1
      12 |     4 |     ...       |  -267140279466343315 |        1 |     0 | 3
      13 |     4 |     ...       | -6865789780959143221 |        1 |     0 | 5
      14 |     4 |     ...       | -2040929596673704583 |        1 |     0 | 7
      15 |     4 |     ...       | -3750366477942382121 |        1 |     0 | 9
      16 |     6 |     ...       |  2241733668526071317 |        1 |     0 | 1
      17 |     6 |     ...       |  -267140279464343305 |        1 |     0 | 3
      18 |     6 |     ...       | -6865789780961143231 |        1 |     0 | 5
      19 |     6 |     ...       | -2040929596671704637 |        1 |     0 | 7
      20 |     6 |     ...       | -3750366477944382131 |        1 |     0 | 9
      21 |     8 |     ...       |  2241733668516071355 |        1 |     0 | 1
      22 |     8 |     ...       |  -267140279462343303 |        1 |     0 | 3
      23 |     8 |     ...       | -6865789780947143121 |        1 |     0 | 5
      24 |     8 |     ...       | -2040929596677704595 |        1 |     0 | 7
      25 |     8 |     ...       | -3750366477938382045 |        1 |     0 | 9
      26 |    10 |     ...       |  -179833476364920441 |        1 |     0 | 1
      27 |    10 |     ...       |  4666783280000472973 |        1 |     0 | 3
      28 |    10 |     ...       | -6021067085825160933 |        1 |     0 | 5
      29 |    10 |     ...       | -6401888343550871263 |        1 |     0 | 7
      30 |    10 |     ...       | -7084909074444200609 |        1 |     0 | 9
     (30 rows)

Of course, you can select the columns you want to see, rename and
reorder them. For instance, you don't really care of ``jobman_hash``,
which is an internal field, or ``jobman_experiment``, since it is the
same for all experiments.

.. code-block:: sql

    <database>=> SELECT id, jobman_status AS status, jobman_sql_priority AS
    priority, first, second FROM test_add_view;

     id | status | priority | first | second 
    ----+--------+----------+-------+--------
      1 |      0 |        1 |     0 |      1
      2 |      0 |        1 |     0 |      3
      3 |      0 |        1 |     0 |      5
      4 |      0 |        1 |     0 |      7
      5 |      0 |        1 |     0 |      9
      6 |      0 |        1 |     2 |      1
      7 |      0 |        1 |     2 |      3
      8 |      0 |        1 |     2 |      5
      9 |      0 |        1 |     2 |      7
     10 |      0 |        1 |     2 |      9
     11 |      0 |        1 |     4 |      1
     12 |      0 |        1 |     4 |      3
     13 |      0 |        1 |     4 |      5
     14 |      0 |        1 |     4 |      7
     15 |      0 |        1 |     4 |      9
     16 |      0 |        1 |     6 |      1
     17 |      0 |        1 |     6 |      3
     18 |      0 |        1 |     6 |      5
     19 |      0 |        1 |     6 |      7
     20 |      0 |        1 |     6 |      9
     21 |      0 |        1 |     8 |      1
     22 |      0 |        1 |     8 |      3
     23 |      0 |        1 |     8 |      5
     24 |      0 |        1 |     8 |      7
     25 |      0 |        1 |     8 |      9
     26 |      0 |        1 |    10 |      1
     27 |      0 |        1 |    10 |      3
     28 |      0 |        1 |    10 |      5
     29 |      0 |        1 |    10 |      7
     30 |      0 |        1 |    10 |      9
    (30 rows)

The ``priority`` decides the order in which the jobs will be executed, higher means first.

The ``status`` is the execution status. 0 means ready to execute, 1
means that the execution has started, 2 that it's completed, 3 that there was an
error while starting the job, 4 that there was en error while doing the rsync of
the job working directory, 5 that the job did not return COMPLETE or INCOMPLETE
(it can have raised an error) and -1 that the job have been canceled.


Canceling/Restarting jobs
-------------------------

.. code-block:: bash

   jobman sqlstatus [--all] [--print=KEY] [--print-keys] [--status=JOB_STATUS] [--set_status=JOB_STATUS] [--resert_prio] [--select=key=value] [--quiet] [--ret_nb_jobs] postgres://<user>:<pass>@<server>/<database>?table=<table> JOB_ID1, JOB_ID2, ...

* Default: only print the current status of those jobs.
* `--all`: add all jobs in the db to the list of jobs.
* `--print=KEY`: print the value of KEY of jobs in the db. Accept multiple --print option.
* `--print-keys`: print the keys in the state of the first job.
* `--status=JOB_STATUS`: Query the db and add jobs with the status JOB_STATUS to the list jobs.
* `--set_status=JOB_STATUS`: print and change the status of jobs.to CANCELED. 
    * --set_status=CANCELED: This means that  `jobman sql` won't start those jobs.
      If the jobs are 
      already running, when the jobs finish it will change the status to START 
      or DONE depending of what it return. If the already running jobs crash,
      it won't change the status.
    * --set_status=START: This means that `jobman sql` will start those jobs again.
* `--reset_prio`: put the priority of jobs back to the default value.
* `--select=key=value`: Query the db and add jobs that match all select parameter to the list of jobs.
* `--quiet`: less verbose
* `--ret_nb_jobs`: print only the number of jobs selected.

JOB_STATUS={START,RUNNING,DONE,ERR_START,ERR_SYNC,ERR_RUN,CANCELED} or the corresponding number {0,1,2,3,4,5,-1}.

Storing the mercurial/other repository version of python module
---------------------------------------------------------------

In pylearn(TODO: LINK) their is a function that allow you to store into
the state of an experiment the version of the repository of some module.
It will also print on the stdout(jobman will forward it to a file in
some case) the files that are not tracked or modified. This help to
reproduce some experiments result in case the code base change. Jobman
tables provide the parameter tester and the result and this provide the
code version that produced those result.


Querying the results
--------------------

Once the first job has finished execution, new keys are added to its
``state``. To account for them, you should recreate the view, by running
the code above (TODO: put reference).

Three fields have been added: ``jobman_sql_hostname`` and
``jobman_sql_hostworkdir``, which contain the hostname and temporary
working directory the job has been executed on, and ``result``, as
created by the experiment function (``addition_example``).

We can then use SQL syntax to retrieve the results of finished jobs:

.. code-block:: sql

    <database>=> SELECT id, jobman_status AS status, jobman_sql_priority AS
    priority, first, second, result FROM test_add_view WHERE jobman_status=2;

    id | status | priority | first | second | result 
   ----+--------+----------+-------+--------+--------
     1 |      2 |        1 |     0 |      1 |      1
   (1 row)

When several jobs are complete, you can filter and order the results:

.. code-block:: sql

    <database>=> SELECT id, jobman_status AS status, jobman_sql_priority AS
    priority, first, second, result FROM test_add_view WHERE first > 4 AND
    second < 7 AND jobman_status = 2 ORDER BY result;

     id | status | priority | first | second | result 
    ----+--------+----------+-------+--------+--------
     16 |      2 |        1 |     6 |      1 |      7
     21 |      2 |        1 |     8 |      1 |      9
     17 |      2 |        1 |     6 |      3 |      9
     22 |      2 |        1 |     8 |      3 |     11
     18 |      2 |        1 |     6 |      5 |     11
     26 |      2 |        1 |    10 |      1 |     11
     27 |      2 |        1 |    10 |      3 |     13
     23 |      2 |        1 |     8 |      5 |     13
     28 |      2 |        1 |    10 |      5 |     15
    (9 rows)



